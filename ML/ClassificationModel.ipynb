{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+CPCIqiHETMBmpM/81BTW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCkIFJtJwznp","executionInfo":{"status":"ok","timestamp":1748987859682,"user_tz":240,"elapsed":7254,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"563a4cf7-57ad-45c4-8052-ee2bf0649a22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.0\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","         Low       0.00      0.00      0.00       0.0\n","      Medium       0.00      0.00      0.00       1.0\n","\n","    accuracy                           0.00       1.0\n","   macro avg       0.00      0.00      0.00       1.0\n","weighted avg       0.00      0.00      0.00       1.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["#### ML Model creation for Classification tasks ###\n","# Works with LogisticRegression, Randomforest and XGBoost\n","# Sriram Parthasarathy\n","# LICENSES : MIT\n","\n","'''\n","Classification assigns data points to predefined categories (discrete labels) based on input features.\n","When to use: Use when the output is categorical (e.g., yes/no, spam/not spam, disease type).\n","Examples:\n","\n","- Email spam detection (spam vs. legitimate).\n","\n","- Medical diagnosis (benign vs. malignant tumor).\n","\n","- Sentiment analysis (positive/negative/neutral reviews).\n","\n","Additional Reading:\n","Please refer to my articles on Medium for more details:\n","The Shopping Cart Abandonment Problem: How Machine Learning Can Help!\n","https://medium.com/managing-digital-products/the-shopping-cart-abandonment-problem-how-machine-learning-can-help-eb690f1dc4f6?source=your_stories_page--------------------------------------------\n","\n","How to Measure & Optimise Your Predictive Model for Prime Time?\n","https://medium.com/managing-digital-products/how-to-measure-optimise-your-predictive-model-for-prime-time-3b9f6072f85c?source=your_stories_page--------------------------------------------\n","\n","Increasing The Accuracy of Predictive Models with Stacked Ensemble Techniques: Healthcare Example\n","https://medium.com/managing-digital-products/increasing-the-accuracy-of-predictive-model-with-stacked-ensemble-techniques-a-healthcare-example-135d36b9a2b7?source=your_stories_page--------------------------------------------\n","\n","AI Powered Automatic Classification: The Challenges in Managing Data in Clinical Trials\n","https://medium.com/managing-digital-products/ai-powered-automatic-classification-the-challenges-in-managing-data-in-clinical-trials-6639e7aa1a7d?source=your_stories_page--------------------------------------------\n","\n","How Do You Measure If Your Customer Churn Predictive Model Is Good?\n","https://medium.com/data-science/how-do-you-measure-if-your-customer-churn-predictive-model-is-good-187a49a9eee3?source=your_stories_page--------------------------------------------\n","\n","\n","Practical Data Augmentation Techniques for Predictive Models\n","https://medium.com/hackernoon/practical-data-augmentation-techniques-for-predictive-models-b51599253c30?source=your_stories_page--------------------------------------------\n","\n","Machine Learning for Product Managers: Defining the business problem\n","https://medium.com/managing-digital-products/machine-learning-for-product-managers-defining-the-business-problem-f0e968d09ee7?source=your_stories_page--------------------------------------------\n","\n","'''\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# ----------------------------\n","# STEP 1: Create sample dataset\n","# ----------------------------\n","# To illustrate I am using sample dataset as I can't share a real customer dataset\n","# Replace this with your data\n","\n","data = {\n","    'education': ['Bachelors', 'Masters', 'PhD', 'Bachelors', 'Masters'],\n","    'years_experience': [1, 3, 5, 2, 7],\n","    'salary': [30000.0, 50000.0, 70000.0, 35000.0, 90000.0],\n","    'performance_label': ['Low', 'Medium', 'High', 'Low', 'High']  # Categorical target\n","}\n","df = pd.DataFrame(data)\n","\n","# ----------------------------\n","# STEP 2: Define features and target\n","# ----------------------------\n","X = df.drop(columns=['performance_label'])\n","y = df['performance_label']\n","\n","# ----------------------------\n","# STEP 3: Preprocessing pipeline\n","# ----------------------------\n","categorical_cols = ['education']\n","numeric_cols = ['years_experience', 'salary']\n","\n","# Proprocess the data for categorical and numerical columns\n","preprocessor = ColumnTransformer([\n","    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n","    ('num', StandardScaler(), numeric_cols)\n","])\n","\n","# For RandomForest and XG Boost we can potentially skip the numeric scaler\n","\n","# Apply OneHotEncoder to categoricals and pass through numericals for Randomforest\n","# preprocessor = ColumnTransformer([\n","#     ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n","# ], remainder='passthrough')  # keep numeric columns as-is\n","\n","\n","\n","\n","\n","# ----------------------------\n","# STEP 4: Build and train model\n","# ----------------------------\n","pipeline = Pipeline([\n","    ('preprocess', preprocessor),\n","    ('classifier', LogisticRegression(max_iter=1000))\n","])\n","\n","\n","\n","#RandomForestClassifier\n","# pipeline = Pipeline([\n","#     ('preprocess', preprocessor),\n","#     ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n","# ])\n","\n","#XGBClassifier\n","# pipeline = Pipeline([\n","#     ('preprocess', preprocessor),\n","#     ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n","# ])\n","\n","\n","# Split dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Fit model\n","pipeline.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = pipeline.predict(X_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","\n","\n","# Accuracy\n","# What it means: % of correct predictions.\n","# Good when: Classes are balanced.\n","\n","\n","# Precision\n","# What it means: How many predicted positives are actually correct.\n","# Good when: False positives are costly.\n","# Example: In cancer detection, you don’t want to falsely say someone has cancer.\n","\n","\n","# Recall (Sensitivity)\n","# What it means: How many actual positives the model found.\n","# Good when: False negatives are costly.\n","# Example: You don’t want to miss a real cancer case.\n","\n","\n","# F1 Score\n","# What it means: Balance between Precision and Recall.\n","# Good when: You need a balance between FP and FN.\n","\n","\n","# ROC-AUC (Receiver Operating Characteristic – Area Under Curve)\n","# What it means: How well the model separates classes at different thresholds.\n","# Good when: You want to understand the model’s overall ability to discriminate.\n"]}]}